---
title: 'Lab Assignment #6'
author: "Math 437 - Modern Data Analysis"
date: "Due March 15, 2023"
output: pdf_document
---

# Instructions

The purpose of this lab is to introduce a few different classification strategies. In this lab we will work with k-nearest neighbors, logistic regression, and their generalizations to more than 2 response categories.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries and data, message = FALSE, warning = FALSE}
library(ISLR2)
library(ggplot2)
library(dplyr)
library(class) # knn
library(nycflights13) # Problem 3
library(nnet) # multinomial logistic regression
library(workflows)
library(parsnip)
library(recipes)
library(rsample)
library(broom)
```

This lab assignment is worth a total of **20 points**.

# Problem 1: Example Code 

## Part a (Code: 1.5 pts)

Run the code in ISLR Labs 4.7.1, 4.7.2, and 4.7.6. Put each chunk from the textbook in its own chunk.

4.7.1 
```{r}
names(Smarket)
dim(Smarket)
summary(Smarket)
pairs(Smarket)
```

```{r eval = FALSE}
cor(Smarket)
```

```{r}
cor(Smarket[, -9])
```

```{r}
attach(Smarket)
plot(Volume)
```

4.7.2 Logistic Regression
```{r}
glm.fits <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
                data = Smarket, family = binomial)
summary(glm.fits)
```

```{r}
coef(glm.fits)

summary(glm.fits)$coef

summary(glm.fits)$coef[, 4]
```

```{r}
glm.probs <- predict(glm.fits, type = "response")
glm.probs[1:10]
contrasts(Direction)
```


```{r}
glm.pred <- rep("Down", 1250)
glm.pred[glm.probs > .5] = "Up"
```

```{r}
table(glm.pred, Direction)

mean(glm.pred == Direction)
```


```{r}
train <- (Year < 2005)

Smarket.2005 <- Smarket[!train, ]
dim(Smarket.2005)

Direction.2005 <- Direction[!train]
```

```{r}
glm.fits <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
                data = Smarket, family = binomial, subset = train)

glm.probs <- predict(glm.fits, Smarket.2005, type = "response")
```

```{r}
glm.pred <- rep("Down", 252)

glm.pred[glm.probs > .5] <- "Up"

table(glm.pred, Direction.2005)

mean(glm.pred == Direction.2005)

mean(glm.pred != Direction.2005)

```

```{r}
glm.fits <- glm(Direction ~ Lag1 + Lag2, data = Smarket, family = binomial,
                subset = train)

glm.probs <- predict(glm.fits, Smarket.2005, type = "response")

glm.pred <- rep("Down", 252)

glm.pred[glm.probs > .5] <- "Up"

table(glm.pred, Direction.2005)

mean(glm.pred == Direction.2005)

106/ (106 + 76)
```

```{r}
predict(glm.fits, newdata = data.frame(Lag1 = c(1.2, 1.5), Lag2 = c(1.1, -0.8)),
        type = "response")
```
4.7.6 K-Nearest Neighbors
```{r}
train.X <- cbind(Lag1, Lag2)[train, ]
test.X <- cbind(Lag1, Lag2)[!train, ]
train.Direction <- Direction[train]
```

```{r}
set.seed(1)
knn.pred <- knn(train.X, test.X, train.Direction, k = 1)

table(knn.pred, Direction.2005)

(83 + 43) / 252
```

```{r}
knn.pred <- knn(train.X, test.X, train.Direction, k = 3)
table(knn.pred, Direction.2005)

mean(knn.pred == Direction.2005)
```

```{r}
dim(Caravan)
```

```{r}
attach(Caravan)

summary(Purchase)

348 / 5822
```

```{r}
standardized.X <- scale(Caravan[, -86])

var(Caravan[, 1])
var(Caravan[, 2])

var(standardized.X[, 1])
var(standardized.X[, 2])
```
```{r}
test <- 1:1000

train.X <- standardized.X[-test, ]
test.X <- standardized.X[test, ]

train.Y <- Purchase[-test]
test.Y <- Purchase[test]

set.seed(1)
knn.pred <- knn(train.X, test.X, train.Y, k = 1)

mean(test.Y != knn.pred)

mean(test.Y != "No")
```

```{r}
table(knn.pred, test.Y)

9 / (68 + 9)
```

```{r}
knn.pred <- knn(train.X, test.X, train.Y, k = 3)
table(knn.pred, test.Y)

5 / 26

knn.pred <- knn(train.X, test.X, train.Y, k = 5)

table(knn.pred, test.Y)

4 / 15
```

```{r}
glm.fits <- glm(Purchase ~., data = Caravan, family = binomial, subset = -test)

glm.probs <-  predict(glm.fits, Caravan[test, ], type = "response")

glm.pred <- rep("No", 1000)

glm.pred[glm.probs > .5] <- "Yes"

table(glm.pred, test.Y)

glm.pred <- rep("No", 1000)

glm.pred[glm.probs > .25] <- "Yes"

table(glm.pred, test.Y)

11 / (22 + 11)

```


## Part b (Explanation: 1 pt)

In Lab 4.7.6, both the k-nn model with `k = 5` and the logistic regression model using `probs > 0.5` as the classification threshold produced a test error rate (misclassification rate) of 6.6% using the `Caravan` dataset. Explain why we would prefer to use the k-nn model.

We may prefer to use a nonparametric method such as KNN so we are 
not making assumptions about the structure/distribution of our response or predictors.

## Part c (Explanation: 1 pt)

If you forget to include the `family = binomial` argument when calling `glm`, what does R try to do instead of running a logistic regression? It may be useful to look up the documentation for the `glm` function, look up the part of the Logistic Regression Class Activity where we actually did this, and/or read Section 4.6.3 of the textbook.

When a family is not specified, R will default to running a linear
regression instead. 

# Problem 2: Analysis of iris Dataset: virginica vs versicolor

The `iris` dataset is a well-known benchmark dataset for evaluating the performance of new classification algorithms on small sets of data. It is found in the `datasets` package (which should automatically be loaded when you start R).

The dataset consists of five variables: the response variable (`Species`) and four explanatory variables (`Sepal.Length`, `Sepal.Width`, `Petal.Length`, and `Petal.Width`, each measured in cm). Because the species are fairly distinct in terms of the four explanatory variables, we should expect near-100% accuracy with any decent classification model.

In this problem, we will do all of our modeling without using the `tidymodels` packages.

## Part a (Code: 2 pts)

We will start out by working with only the species `virginica` and `versicolor`. Create a new dataset, `iris_vv`, by filtering to only include those two species. Then, pick two of the explanatory variables and, using the `ggplot2` package, create a scatterplot showing the relationship between those two variables, color-coded based on the `Species`.

```{r}
iris_vv <- iris %>% 
  filter(Species == "virginica" | Species == "versicolor")

ggplot(iris_vv, aes(x=Sepal.Length, y=Sepal.Width, color=Species)) +
  geom_point() 
```


## Part b (Code: 2 pts)

Prepare your dataset for the k-nearest neighbors algorithm by doing the following:

### Step 1: Create the training and holdout sets

Randomly select 20 observations to be in the holdout set. The remaining observations are in the training set. Call these new datasets `iris.train` and `iris.test`.

HINT: The easiest way to do this is to `sample` from the indices and subset accordingly.

```{r}
set.seed(1003)
n <- nrow(iris_vv)
test.rows <- sample(n, floor(20), replace = FALSE)
iris.train <- iris_vv[-test.rows,]
iris.test <- iris_vv[test.rows,]
```


### Step 2: Scale the predictor variables

Create two new datasets, `iris.train.X` and `iris.test.X`, containing the explanatory variables in each set. Remember that you need to scale the variables in both the training and holdout sets based on the training set!

```{r}
iris.train.X <- iris.train %>% 
  select(-Species) %>%
  scale()

iris.test.X <- iris.test %>% 
  select(-Species) %>% 
  mutate(Sepal.Length = (Sepal.Length-mean(iris.train$Sepal.Length))/sd(iris.train$Sepal.Length),
         Sepal.Width = (Sepal.Width-mean(iris.train$Sepal.Width))/sd(iris.train$Sepal.Width),
         Petal.Length = (Petal.Length-mean(iris.train$Petal.Length))/sd(iris.train$Petal.Length),
         Petal.Width = (Petal.Width-mean(iris.train$Petal.Width))/sd(iris.train$Petal.Width)
         )
```


## Part c (Code: 2 pts; Explanation: 0.5 pts)

With the `knn` function, use 5-nearest neighbors to predict the species of each observation in the `iris.test` holdout set. Create a `table` showing the predicted and actual species in the holdout set. What is the prediction accuracy of this model?

```{r}
train_response <- iris.train %>% 
  mutate(as.factor(Species)) %>% 
  select(Species)


k1 <- knn(train = iris.train.X, test = iris.test.X, k=5, cl = train_response, prob = TRUE)
length(iris.train.X)

new_name <- fit(k1, data = iris.train.X)

```


## Part d (Code: 1 pt; Explanation: 1 pt)

Fit a logistic regression model on the training set predicting `Species` from the four explanatory variables. Unlike with k-nearest neighbors, you do not need to scale the variables. Note that there may be some weirdness with figuring out the reference level for `Species`, so you may want to use the `relevel` function to set that before fitting the model.

Use the `summary` or `coef` function to obtain the coefficient estimates, and write out the equation of the fitted logistic regression model.

## Part e (Code: 2 pts; Explanation: 0.5 pts)

Use the `predict` function to obtain predictions for the `iris.test` holdout set. Remember to include the argument `type = "response"` to output predictions as probabilities!

Predict the class of each flower in the holdout set using a decision boundary of 0.5 (i.e., if the predicted probability of being in *versicolor* vs. *virginica* is above 0.5, predict the flower to be in *versicolor*). Create a `table` showing the predicted and actual species in the holdout set. What is the prediction accuracy of this model on the holdout set?

# Problem 3: Analysis of flights Dataset

There are three major airports that serve the New York City metro area: John F. Kennedy International Airport (JFK), Newark Liberty International Airport (EWR), and LaGuardia Airport (LGA). Newark is a United Airlines hub, JFK is an American Airlines hub, while Delta has hubs at both JFK and LGA.

The `flights` dataset contains flights from 2013 that departed one of those three airports. Here we filter the dataset to include only flights that departed on one of those three carriers. 

```{r filter flights}
flights2 <- flights %>% filter(
  carrier %in% c("UA", "AA", "DL"),
  !is.na(dep_delay)
) %>%
  mutate(origin = as.factor(origin))
```

Let's try to predict which airport a flight departed from into based on the carrier as well as the distance the flight has covered and the departure delay. In this problem we'll do everything the `tidymodels` way.

## Part a (Code: 1 pt)

First, we'll use 3-nearest neighbors to predict the departure airport of each observation in the `flights_test` holdout set.

```{r pre-processing and model spec}
knn_model <- nearest_neighbor(mode = "classification", neighbors = 3, dist_power = 2)

set.seed(2222)
flights_split <- initial_split(flights2, prop = 0.8)
flights_train <- training(flights_split)
flights_test <- testing(flights_split)

knn_prep <- recipe(
  origin ~ carrier + distance + dep_delay, # response ~ predictors
  data = flights_train
) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors()) # center and scale numeric predictors

flights_knn <- workflow() %>%
  add_model(knn_model) %>%
  add_recipe(knn_prep)
```

In the chunk below, write code that will `fit` the model on the training set. (If your model runs for ~3 seconds without an error message, start on part (b) while you wait for the chunk to churn.)

```{r fitting k-nn}

```

Next, use the `augment` function to create the tibble `flights_knn_predictions` containing the predictions for each flight in the `flights_test` dataset. 

```{r predicting with broom::augment}

```

## Part b (Explanation: 1 pt)

While you wait for your code to run, as best you can, answer the following questions:

* How did we ensure that roughly 20% of the data was in the holdout set, even though we didn't know the exact size of my dataset?

* What does the `step_dummy` function do, and why did we need to do it?

## Part c (Code: 0.5 pts; Explanation: 0.5 pts)

Now let's use multinomial logistic regression to do the same predictions. Multinomial logistic regression requires much less fuss than k-nearest neighbors when it comes to data prep. Remember, since this uses *regression* frameworks, rescaling the variables just messes with intercept and slopes! 

The two main functions I use to do this are `VGAM::vglm` and `nnet::multinom`. I find that `vglm` is more generalizable, but it doesn't play nice with `tidymodels`, so we'll use `multinom` instead.

```{r fit multinomial}
# just run this - it all works
multinom_model <- multinom_reg(mode = "classification") # everything else is default

multinom_prep <- recipe(
  origin ~ carrier + distance + dep_delay, # response ~ predictors
  data = flights_train
) %>%
  step_dummy(all_nominal_predictors())

flights_multinom <- workflow() %>%
  add_model(multinom_model) %>%
  add_recipe(multinom_prep)
```

In the chunk below, write code that will `fit` the model on the training set and store the result in the object `flights_multinom_fit`.

```{r fit the model}

```

What reference (baseline) level was chosen?

## Part d (Code: 0.5 pts)

Getting the coefficients out as a separate R object is a bit of a pain, but we can do it:

```{r multinomial coefficients}
multinom_coef <- extract_fit_engine(flights_multinom_fit) %>% coef()
print(multinom_coef)
```

To interpret our coefficients, we can usually hack our way to *softmax* coding by adding a zero row (corresponding to the reference/baseline level) at the very top of the coefficient matrix. Then we can look at the effect of a change in the predictor variable on the log-odds of being in any response group relative to any other response group.

```{r coef matrix}
coef_softmax <- rbind(EWR = numeric(5),
                      multinom_coef)
print(coef_softmax)
```

Now, for two flights with the same carrier and distance, a one-mile increase in distance is associated with a 0.0017 increase in the log-odds of being from JFK as compared to EWR, and a 0.0006 decrease in the log-odds of being from LGA as compared to EWR. By subtracting the two nonzero slopes, we find that a one-mile increase in distance is associated with a $0.0017 - (-0.0006)$ = 0.0023 increase in the log-odds of being from JFK as compared to LGA.

Inference with a multinomial logistic regression model is possible by calling the `multinom` function directly (tidymodels appears to drop the standard errors from the output), but instead we're going to instead focus on prediction.

If we use the `multinom` function directly, then we can use the `predict` function just like in linear and logistic regression, but we have to use either `class` or `probs` as our `type` argument - we can't use `response` and then pick an arbitrary boundary threshold, since now we have multiple boundaries between different groups.

The `augment` function does away with this ridiculousness and gives us both class predictions and the predicted probability of being in each class without having the remember what argument to use for `type`. Using the `augment` function, create the tibble `flights_multinom_predictions` containing the predictions for each flight in the `flights_test` dataset. 

```{r multinom prediction}

```


```{r multinom predictions 43-45}
flights_multinom_predictions %>% dplyr::select(
  origin,
  .pred_class,
  .pred_EWR,
  .pred_JFK,
  .pred_LGA
) %>%
  slice(43:45) # equivalent to data[43:45,] but works with a pipe
```

When we have multi-class classification problems, it is possible that no class reaches a 50% probability (e.g., observation 44). In these situations, observations are still classified to the *most likely* airport, we just note that there is a lot more uncertainty about the prediction. 

## Part e (Code: 1 pt)

Using the `accuracy` function in the `yardstick` package, find the prediction accuracy of each model.

## Part f (Explanation: 1 pt)

Briefly discuss the advantages of using the 3-nearest neighbors algorithm over the multinomial logistic regression model on the `flights` data, and the advantages of using the multinomial logistic regression model over the 3-nearest neighbors algorithm. Prediction accuracy is important, but not the only thing you should compare.
