---
title: 'Lab Assignment #5'
author: "Nick Noel & Liz VIlla"
date: "Due March 8, 2023"
output: pdf_document
---

# Instructions

The purpose of this lab is to introduce more advanced regression strategies that were probably not covered in Math 338.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this lab, we will be working with four datasets. Three (`Boston`, `Carseats`, and `Wage`) are contained in the `ISLR2` package. Information about these datasets can be found by searching R help for them.

The fourth dataset, `RateMyProfessor`, needs to be downloaded from Canvas. This dataset contains the overall average rating from <https://www.ratemyprofessors.com/> for over 22,000 professors, as collected by [Murray et al. (2020)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0233515). A data dictionary for the dataset can be found at <https://github.com/murrayds/aa_rmp/tree/master/data> (note that I removed a bunch of variables so that you're downloading a 2 MB dataset instead of a much larger one).


```{r libraries and data, message = FALSE, warning = FALSE, eval = FALSE}
library(ISLR2)
library(ggplot2)
library(dplyr)
library(broom) # See Problem 3b

RateMyProfessor <- read.csv("RateMyProfessor.csv")
```

This lab assignment is worth a total of **15 points**.

# Problem 1: Indicator Variables

## Part a (Code: 0.5 pts)

Run the code in ISLR Lab 3.6.6. Put each chunk from the textbook in its own chunk.

```{r, include = FALSE}
library(ISLR2)
library(tidyverse)
library(broom)
head(Carseats)
```

```{r}
lm.fit <- lm(Sales ~ . + Income:Advertising + Price:Age, data = Carseats)

summary(lm.fit)
```

```{r}
attach(Carseats)

contrasts(ShelveLoc)
```



## Part b (Explanation: 1 pt)

Interpret the slope estimate corresponding to `ShelveLocGood` in the model fit in part (a).

When compared to a bad shelf location, placing a child car seat in a good shelf location increases the expected sales by about 5 car seats.

## Part c (Code: 1 pt; Explanation: 1.5 pts)

Using the RateMyProfessor dataset, fit a linear model predicting the overall rating of a professor (`overall`) from the difficulty rating (`difficulty`), chili pepper rating (`hotness`), and rank (`rank`). What are the reference levels for each categorical variable? How do you know?

```{r}
RateMyProfessor <- read.csv("RateMyProfessor.csv")

lm.fitrmp <- lm(overall ~ difficulty + hotness + rank, data = RateMyProfessor)

summary(lm.fitrmp)

unique(RateMyProfessor[c("hotness", "rank")])
```

The reference level for hotness is cold and for rank it is assistant professor.
We know this because these categories do not appear in the coefficients,
indicating that they were selected as the reference levels for the remaining
categories to be compared to.


## Part d (Explanation: 1.5 pts)

Holding difficulty constant, which of the following instructors would be predicted to have the highest overall rating? Which would be predicted to have the lowest overall rating? Explain your reasoning.

* Attractive Assistant Professor
* Attractive Associate Professor
* Attractive Professor
* Less-attractive Assistant Professor
* Less-attractive Associate Professor
* Less-attractive Professor

Attractive Assistant Professors would be predicted to have the highest overall
rating since holding all else constant, being an associate professor or professor
decreases the average overall rating, and being hot increases the average overall
rating. A less-attractive associate professor would be predicted to have the 
lowest overall rating since being rated as hot increases the average overall
rating compared to being less attractive and compared to being an assistant
professor, associate professors on average have lower overall ratings than
professors.


# Problem 2: Interaction Terms

## Part a (Code: 0.5 pts)

Run the single line of code in ISLR Lab 3.6.4. 

```{r}
summary(lm(medv~lstat * age , data = Boston))

summary(lm(medv~lstat + age , data = Boston))

```


## Part b (Explanation: 2 pts)

Notice that `age` is a significant predictor of `medv` in the model without the interaction term (from ISLR Lab 3.6.3 on Lab 4), but it is no longer a significant predictor of `medv` once we add in the interaction term. The p-value is huge (0.971!). What do you think is happening here? Are we okay to remove the `age` variable from the model with the interaction term? Why or why not?

The result of adding our interaction term, age:lstat, yields us the same amount of significance regarding our model but has the added benefit of accounting for the interaction between the two terms. In all honesty, it seems like the model can go with or without the the interaction term as we are still seeing age be a significant factor, just regarding the interaction in this new model. We cannot take out just the age variable and leave in the interaction term though as a result of the hierarchical principal that states such.



## Part c (Code: 1 pt; Explanation: 1.5 pts)

Create a new dataset, `associates`, by `filter`ing the `RateMyProfessor` dataset to include only the Associate Professors.

```{r}
RateMyProfessor <- read.csv("RateMyProfessor.csv")
associates <- RateMyProfessor %>% 
  filter(rank == "Associate Professor")
```


Next, complete this code chunk to create a graph of overall rating vs. difficulty rating for the associate professors, with "hot" professors shown in red and "cold" professors shown in blue. Remember to delete `eval = FALSE` once you get the code to run!

```{r ggplot associates}
ggplot(data = associates, aes(x = difficulty, y = overall)) +
  geom_point(alpha = .25, aes(color = hotness)) +
  geom_smooth(method = "lm", se = FALSE,aes(color = hotness)) +
  scale_color_manual(name = "Chili Pepper Rating",  # make legend nice
                     labels = c(hot = "Attractive", 
                                cold ="Less-attractive"),
                     values = c(hot = "red", cold = "blue")) + 
  ggtitle("How Hot are the Good Teachers?")
  # scale_fill_manual(breaks = c("cold", "hot"), 
  #                      values=c("blue", "red"))
```

How does the difficulty of the professor modify the relationship between attractiveness and overall rating?

The difficulty of a professor does not seem to be too dependent on attractiveness but their overall rating definitely seems to show teachers with lower overall ratings having higher difficulties compared to teachers with higher ratings having less difficulty.

As difficulty increases, overall rating also decreases. Attractiveness affects that as more attractive professors will have a slope less steep than a cold professor.

## Part d (Code: 1 pt; Computation and Explanation: 2 pts)

Using the `RateMyProfessor` dataset, fit a linear model predicting overall rating from the difficulty rating (`difficulty`), chili pepper rating (`hotness`), rank (`rank`), and an interaction term between `difficulty` and `hotness`.

```{r}

# hist(RateMyProfessor$overall)

lm_for_teachers <- lm(overall ~ difficulty + hotness + rank + difficulty:hotness , data = RateMyProfessor)
summary(lm_for_teachers)
```

Using your results, write out the least-squares regression equation predicting overall rating from difficulty for an attractive associate professor. Also, write out the least-squares regression equation predicting overall rating from difficulty for a less-attractive associate professor. Explain how you obtained each equation.

Total formula :

overall = 5.4708 - .6408(difficulty) - .2524(hot?) -.0489(Associate Professor?) - .0443(Professor) +.2971(difficulty)(hot?)

For an attractive associate professor: 

overall = 5.4708 - .6408(difficulty) -.2524(1) - .0489(1) - 0 +.2971(difficulty)(1)

overall =5.1695- 0.3437(difficulty) 



Do your equations support your conclusions from part (c)? Explain why or why not.

Our equations do in fact support our conclusion from part c for the most part. Being attractive changes our slope by increasing (making less steep of a decline) which can be seen in our plot. 

# Problem 3: Regression with Nonlinear Transformations of the Predictors

## Part a (Code: 0.5 pts)

Run the first four code chunks in ISLR Lab 7.8.1 (up through the point where `fit2b` is created). Put each chunk from the textbook in its own chunk.

```{r}
library(ISLR2)

fit <- lm(wage~poly (age, 4), data = Wage)
coef(summary(fit))
```

```{r}
fit2 <- lm(wage~poly (age, 4, raw =T), data = Wage)
coef(summary(fit2))
```

```{r}

fit2a <- lm(wage~age+I(age^2)+I(age^3)+age^4, data = Wage)
coef(fit2a)

```

```{r}

fit2b <- lm(wage~cbind(age, age^2, age^3, age^4), data = Wage)

```


## Part b (Code: 1 pt)

In the code chunk below, create a data frame with a single variable, `age`, ranging from 18 to 80, then use the `augment` function (in the `broom` package) to obtain the predicted wage, standard error of the mean wage, and the lower and upper bounds of a 95% confidence interval for the population mean wage at each age. (You can use any of `fit`, `fit2`, `fit2a`, or `fit2b` - they should all give the same predictions.)

```{r}
attach(Wage)
agelims <- range(Wage$age)

#create a data frame with a single variable, `age`, ranging from 18 to 80
age.grid <-data.frame(age = seq(from = agelims[1], to = agelims[2]))

#Use the `augment` function (in the `broom` package) to obtain the predicted wage
preds <- augment(fit2b, new_data = age.grid)




```


What is the 95% confidence interval for the population mean wage of 25-year-olds? 50-year-olds?

```{r use augment to get predictions out}

broom::augment(fit2b, newdata = age.grid, interval = "confidence")

```
For age 25:	88.47380	85.21437	91.73322

For age 50: 119.57013	117.35377	121.78650