---
title: 'Lab Assignment #7'
author: "Nick Noel & Liz Villa"
date: "Due March 24, 2023"
output:
  pdf_document: default
  html_document: default
---

# Instructions

The purpose of this lab is to introduce several different classification strategies and variations on classification accuracy. In this lab we will work with another staple set of strategies: Naive Bayes and linear/quadratic discriminant analysis.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries and data, message = FALSE, warning = FALSE}
library(ISLR2)
library(ggplot2)
library(dplyr)
library(nycflights13)
library(e1071) # Naive Bayes
library(MASS) # LDA/QDA
library(yardstick) # only tidymodels package we'll need in this lab
```

This lab assignment is worth a total of **25 points**.

# Problem 1: Naive Bayes

## Part a (Code: 1 pt)

Run the code in ISLR Lab 4.7.5.

```{r}
attach(Smarket)
train <- (Smarket$Year <2005)
Smarket.2005 <- Smarket[!train,]
Direction.2005 <- Direction[!train]
library(e1071)
```


```{r}
nb.fit <- naiveBayes(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)


nb.fit
```


```{r}
mean(Lag1[train][Direction[train] == "Down"])

sd(Lag1[train][Direction[train] == "Down"])
```


```{r}
nb.class <- predict(nb.fit,Smarket.2005)

table(nb.class, Direction.2005)

mean(nb.class == Direction.2005)
```

```{r}
nb.preds <- predict(nb.fit, Smarket.2005, type = "raw")
nb.preds[1:5,]
```



## Part b (Code: 1 pt)

Recall that in Lab 6 we filtered the flights to only the United, American, and Delta carriers. Here we add another variable, `arr_ontime`, to represent whether the flight arrived on time or not.

```{r filter flights}
flights2 <- flights %>% filter(
  carrier %in% c("UA", "AA", "DL"),
  !is.na(dep_delay),
  !is.na(arr_delay)
) %>%
  mutate(
    arr_ontime = as.factor(if_else(arr_delay <= 0, "yes", "no"))
  )
```

Non-randomly divide the `flights2` dataset into `flights_training`, which contains all flights through October, and `flights_test`, which contains all flights in November and December. You should be able to use the `filter` function to do this.

```{r}
flights2$arr_ontime <- relevel(flights2$arr_ontime, ref = "yes")
flights_training <- flights2 %>% 
  filter(month == 10)
flights_test <- flights2 %>% 
  filter(month == 11 | month == 12)
```


Then, fit a Naive Bayes model on the training set predicting whether a flight will be delayed (`arr_ontime` = "no") based on the departure delay (`dep_delay`), `carrier`, `distance` traveled, and `origin`.

```{r}
nb.flit <- naiveBayes(arr_ontime ~ dep_delay + carrier + distance +
                        origin, data = flights_training)
```


## Part c (Code: 1.5 pts)

Unfortunately, there is no easy way to use `augment` on this model, so we'll have to make the predictions ourselves.

First, make class predictions on the `flights_test` dataset using similar code to that done in Lab 4.7.5. Then, create the `flights_nb_predictions` data frame or tibble containing two columns: `predicted`, representing the predicted classes, and `actual`, representing the actual classes. Use `flights_nb_predictions` to obtain the confusion matrix for the model.
```{r}
nb.flass <- predict(nb.flit, flights_test)

flights_nb_predictions <- data.frame(
  predicted = nb.flass,
  actual = flights_test$arr_ontime
)

(cmtrx <- conf_mat(flights_nb_predictions, truth = actual,
         estimate = predicted))

```


## Part d (Code: 0.5 pts; Explanation: 2 pts)

Without running any additional code, use the confusion matrix from part (c) to estimate the sensitivity, specificity, positive predictive value, and negative predictive value for the model. Express all answers as fractions and then convert to decimals rounded to the thousandths place (3 decimal places). 

Sensitivity = 4206/9249 `r round(4206/9249, 3)`

Specificity = 12787/13449  `r round(12787/13449, 3)`

Positive Predictive Value = 4206/4868 `r round(4206/4868, 3)` 

Negative Predictive Value = 12787/17830 `r round(12787/17830, 3)`

Then, using the `summary` function on your confusion matrix, check your answers. Remember that we are trying to predict that a flight will be delayed (`arr_ontime` = "no").

```{r}
summary(cmtrx, event_level = "second")
```

Looking at the summary, 
the sens row estimate matches our sensitivity, the spec row estimate matches our specificity, the ppv row estimate matches our positive predictive value, the npv row estimate matches our negative predictive value. :)

# Problem 2: Discriminant Analysis

## Part a (Code: 1 pt)

Run the code in ISLR Lab 4.7.3.

```{r}
lda.fit <- lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
lda.fit

plot(lda.fit)
```

```{r}
lda.pred <- predict(lda.fit, Smarket.2005)
names(lda.pred)
```

```{r}
lda.class <- lda.pred$class
table(lda.class, Direction.2005)

mean(lda.class == Direction.2005)
```

```{r}
sum(lda.pred$posterior[,1]>=.5)

sum(lda.pred$posterior[,1]<.5)

```
```{r}
lda.pred$posterior[1:20,1]
lda.class[1:20]
```

```{r}
sum(lda.pred$posterior[,1]>.9)
```


## Part b (Code: 1 pt)

Run the code in ISLR Lab 4.7.4.

```{r}
qda.fit <- qda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)

qda.fit
```

```{r}
qda.class <- predict(qda.fit, Smarket.2005)$class

table(qda.class, Direction.2005 )
```

```{r}
mean(qda.class == Direction.2005)
```



## Part c (Code: 1 pt)

Fit a LDA model on the training set predicting whether a flight will be delayed (`arr_ontime` = "no") based on the departure delay (`dep_delay`), `carrier`, `distance` traveled, and `origin`.

```{r}
lda.flit.fit <-lda(arr_ontime ~ dep_delay + carrier + distance + origin, data = flights_training)
  
lda.flit.fit
```


## Part d (Code: 1.5 pts)

Unfortunately, there is no easy way to use `augment` on this model, so we'll have to make the predictions ourselves.

First, make class predictions on the `flights_test` dataset using similar code to that done in Lab 4.7.3. Then, create the `flights_lda_predictions` data frame or tibble containing two columns: `predicted`, representing the predicted classes, and `actual`, representing the actual classes. Use `flights_lda_predictions` to obtain the confusion matrix for the model.

```{r}
lda.flit.pred <- predict(lda.flit.fit, flights_test)


flights_lda_predictions <- data.frame(
  predicted = lda.flit.pred$class,
  actual = flights_test$arr_ontime
)

(cnfsnm <- conf_mat(flights_lda_predictions, truth = actual,
         estimate = predicted))
```


## Part e (Code: 0.5 pts; Explanation: 2 pts)

Without running any additional code, use the confusion matrix from part (d) to estimate the sensitivity, specificity, positive predictive value, and negative predictive value for the model. Express all answers as fractions and then convert to decimals rounded to the thousandths place (3 decimal places). 

Sensitivity = 2541/9249 = `r round(2541/9249, 3)`

Specificity = 13377/13449 = `r round(13377/13449, 3)`

Positive Predictive Value = 2541/2613 = `r round(2541/2613, 3)`

Negative Predictive Value = 13377/20085 = `r round(13377/20085, 3)`

Then, using the `summary` function on your confusion matrix, check your answers. Remember that we are trying to predict that a flight will be delayed (`arr_ontime` = "no").

```{r}
summary(cnfsnm, event_level = "second")
```

Looking at the summary, 
the sens row estimate matches our sensitivity, the spec row estimate matches our specificity, the ppv row estimate matches our positive predictive value, the npv row estimate matches our negative predictive value. :)

## Part f (Code: 3 pts; Explanation: 2 pts)

Repeat parts (c) through (e) for the QDA model. (Obviously, call your new data frame/tibble `flights_qda_predictions` instead.)

(c)
```{r}
qda.flit.fit <-qda(arr_ontime ~ dep_delay + carrier + distance + origin, data = flights_training)
```


(d)
```{r}
qda.flit.pred <- predict(qda.flit.fit, flights_test)


flights_qda_predictions <- data.frame(
  predicted = qda.flit.pred$class,
  actual = flights_test$arr_ontime
)

(cnfsnmq <- conf_mat(flights_qda_predictions, truth = actual,
         estimate = predicted))
```

Sensitivity = 4327/9249 = `r round(4327/9249, 3)` 

Specificity = 12801/13449 = `r round(12801/13449, 3)`

Positive Predictive Value = 4327/4975 = `r round(4327/4975, 3)`

Negative Predictive Value = 12801/17723 = `r round(12801/17723, 3)`

```{r}
summary(cnfsnmq, event_level = "second")
```


# Problem 3: Model Selection

## Part a (Code: 2 pts)

Add a column to the `flights_nb_predictions`, `flights_lda_predictions`, and `flights_qda_predictions` indicating the probability of not arriving on time (`arr_ontime == "no"`). It may be easiest to first obtain the predicted probabilities of being in each class, then add the column to the relevant data frame using `cbind` or `mutate`.

Then, compute the Brier scores for each model. As shown in the class activity, it is easiest to use the `mutate` function to obtain the "squared error" for each observation and then average the squared error.

```{r}
nb.flassprob <- predict(nb.flit, flights_test, type = "raw")

flights_nb_predictions <- flights_nb_predictions %>% 
  mutate(prob_not_aot = nb.flassprob[,"no"])


flights_lda_predictions <- flights_lda_predictions %>% 
  mutate(prob_not_aot = lda.flit.pred$posterior[,2])

flights_qda_predictions <- flights_qda_predictions %>% 
  mutate(prob_not_aot = qda.flit.pred$posterior[,2])
```

```{r Brier Scores}
brier_nb <- flights_nb_predictions %>% 
  mutate(squared_error = case_when(
    predicted == "yes" ~ (prob_not_aot)^2,
    predicted == "no" ~ (1 - prob_not_aot)^2))

brs_nb <- mean(brier_nb$squared_error)

brier_lda <- flights_lda_predictions %>% 
  mutate(squared_error = case_when(
    predicted == "yes" ~ (prob_not_aot)^2,
    predicted == "no" ~ (1 - prob_not_aot)^2))

brs_lda <- mean(brier_lda$squared_error)

brier_qda <- flights_qda_predictions %>% 
  mutate(squared_error = case_when(
    predicted == "yes" ~ (prob_not_aot)^2,
    predicted == "no" ~ (1 - prob_not_aot)^2))

brs_qda <- mean(brier_qda$squared_error)
```


## Part b (Code: 1 pt)

Using the `mn_log_loss` function, obtain the cross-entropy/log loss for each of the three models.

```{r}
lgl_nb <- mn_log_loss(flights_nb_predictions,
            truth = actual,
            prob_not_aot,
            event_level = "second")

lgl_lda <- mn_log_loss(flights_lda_predictions,
            truth = actual,
            prob_not_aot,
            event_level = "second")

lgl_qda <- mn_log_loss(flights_qda_predictions,
            truth = actual,
            prob_not_aot,
            event_level = "second")
```


## Part c (Code: 1 pt)

Using the `mcc` function, obtain the Matthews Correlation Coefficient for each of the three models. 

```{r}
mcc_nb <- mcc(flights_nb_predictions, actual, predicted)

mcc_lda <- mcc(flights_lda_predictions, actual, predicted)

mcc_qda <- mcc(flights_qda_predictions, actual, predicted)
```


## Part d (Explanation: 1.5 pts)

Compare the Brier score, log loss, and Matthews correlation coefficient for the three models by filling in the table below. Round all numbers to 3 decimal places.

| Model | Brier | log loss | MCC |
|:---:|---:|---:|---:|
| Naive Bayes | `r round(brs_nb, 3)` | `r round(lgl_nb$.estimate, 3)` | `r round(mcc_nb$.estimate, 3)` |
| LDA | `r round(brs_lda, 3)` | `r round(lgl_lda$.estimate, 3)` | `r round(mcc_lda$.estimate, 3)` |
| QDA | `r round(brs_qda, 3)` | `r round(lgl_qda$.estimate, 3)` | `r round(mcc_qda$.estimate, 3)` |

Which of the three models performs the best on this test set by each measure?

By Brier Scores, the Naive Bayes and QDA model are tied for best.
By log loss, the LDA model performs best.
By MCC, the QDA model performs best.

## Part e (Explanation: 1.5 pts)

If you had to recommend one of the three models to use to predict whether a flight would be delayed, would you use the Naive Bayes, LDA, or QDA model? Explain.

If we can reasonably assume that our predictors are independent, I would use the Naive Bayes model since it is performing almost as well as the QDA model when measuring accuracy with Brier Scores and MCC and Naive Bayes is less computationally demanding. If we could not make this assumption, or we were working with small data, I would use the QDA model since it performs best according to both measures of accuracy, Brier Scores and MCC.
