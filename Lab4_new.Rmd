---
title: 'Lab Assignment #4'
author: "Nick Noel & Liz Villa"
date: "Due February 27, 2023"
output: html_document
---

# Instructions

The purpose of this lab is to review simple linear regression and multiple linear regression strategies from Math 338/439.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this lab, we will be working with the Boston housing dataset (`Boston` in the `ISLR2` library). This dataset has 506 rows and 13 variables.

```{r libraries and data, message = FALSE, warning = FALSE}
library(ISLR2)
library(ggplot2)
library(dplyr)
library(car) # For problem 3
library(boot)
```

This lab assignment is worth a total of **19.5 points**.

# Problem 1: Bootstrap Estimation of Standard Error

## Part a (Code: 0.5 pts)

Run the code in the first half of ISLR Lab 5.3.4, "Estimating the Accuracy of a Statistic of Interest." Put each chunk from the textbook in its own chunk.

If you are in the actuarial science concentration, you should be familiar with (or will at some point see) this formula! For the rest of us, note that $X$ and $Y$ are assumed to be the yearly return of two different financial assets, and $\alpha$, the quantity to be estimated, is the fraction of money to be invested in $X$ such that the variance (risk) of the total investment $\alpha X + (1 - \alpha) Y$ is minimized. In this problem $\alpha$ is not the significance level!

```{r}
alpha.fn <- function(data, index) {
  X <- data$X[index]
  Y <- data$Y[index]
  (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
}
```

```{r}
alpha.fn(Portfolio, 1:100)
```

```{r}
set.seed(7)
alpha.fn(Portfolio, sample(100, 100, replace = T))
```

```{r}
boot(Portfolio, alpha.fn, R = 1000)
```


## Part b (Code: 2 pts)

According to the instructions for Lab 5.3.4, "We can implement a bootstrap analysis by performing this command [alpha.fn on a bootstrap sample] many times, recording all of the corresponding estimates for $\alpha$, and computing the resulting standard deviation."

Write a code chunk that performs all of those steps and prints out the standard deviation. Use 1000 bootstrap samples. 

```{r}
set.seed(292)
bsn <- 1000
bsalpha <- rep(NA, bsn)
for(i in 1:bsn){bsalpha[i] = alpha.fn(Portfolio, sample(100, 100, replace = T))}
sd(bsalpha)
```

## Part c (Code: 1 pt)

Replicate the center panel of textbook Figure 5.10: a histogram of  the bootstrap estimates of $\alpha$ (from Part b) with a solid pink (or red) line at the true value of $\alpha = 0.6$. You may use either base R plotting commands (which uses `abline` to add the vertical line) or the `ggplot2` package (which adds a `geom_vline` to the plot). 

```{r}
ggplot(mapping = aes(bsalpha)) +
  geom_histogram(bins = 12, fill = "steelblue", color = "black") +
  geom_vline(xintercept = 0.6, color = "pink", size = 1) +
  xlab("alpha")

```


## Part d (Explanation: 1 pt)

Note that the distribution you graphed in Part c is a sampling distribution of $\hat{\alpha}$. Explain why it would be appropriate to use this sampling distribution to construct a confidence interval for $\alpha$, but not to obtain a p-value for a hypothesis test of $H_0: \alpha = 0.6$ against $H_a: \alpha \neq 0.6$.



# Problem 2: Domain Knowledge and Exploratory Data Analysis

## Part a (Explanation: 1 pt)

Do an Internet search for "Boston housing dataset" and answer the following questions as best you can.

* Who collected this data? How old is this dataset?
Answer: Data was collected by the U.S. Census Service concerning housing in the area of Boston Massachusetts in 1978 (Or around then, 1978 was when the data was officially published, possible that the data was collected somewhat earlier.
)
* What does one row in this dataset represent?
Answer: One row in the dataset represents a the data collected for a single house on the multiple variables.


## Part b (Explanation: 1.5 pts)

In your search, you should eventually come across references to a *fourteenth* variable, `B`, which the textbook authors have removed from the dataset. What does this mysterious variable represent?

Answer: According to a data dictionary we found, B was reported as follows:
"B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town". In simpler terms, the variable B is regarding the proportion of black people in a town.

Suppose you are a data scientist at Zillow or a similar company whose housing price models are often used as a reference when people decide how much to offer to buy or sell a home for. What ethical issues would arise from using the variable `B` in your model?

Answer: Using the ethnicity of those around said property as a factor of the value of the property seems like a very unethical way of determining the value of a property. The original research was based around the air pollution of the area so likely dealt with the variable to acknowledge socioeconomic issues as opposed to putting a value on the property.

## Part c (Code: 1 pt; Explanation: 1 pt)

In the next problem we will be trying to predict `medv` from `lstat`. What does the variable `medv` represent? What are the measurement units?

Answer: MEDV - Median value of owner-occupied homes in $1000's


Using the `ggplot2` package, create a histogram of the variable `medv`. Use a `center` of 35 and a `binwidth` of 2.

```{r}
Boston %>% 
  ggplot(aes(x = medv)) +
  geom_histogram(center = 35, binwidth = 2)
```


What looks a bit off about this histogram? Try filling in the `filter` function in the chunk below to confirm your suspicions.

```{r filter Boston medv, eval = FALSE}
Boston %>% 
  filter(medv == 50) %>%
  count() # getting sample size without having to summarize
```

The prices were capped at 50,000 and thus any property worth more than that was lumped into one large group of a value of 50.

## Part d (Code: 1 pt; Explanation: 1 pt)

The full documentation for this dataset is somewhat confusing and raises more questions than answers. For example, `lstat` is defined as "$\frac{1}{2}$ (proportion of adults without some high school education and proportion of male workers classified as laborers)" (whatever that means), and `rad` represents the "index of accessibility to radial highways" as determined by something called the "MIT Boston Project."

Other variables are sensibly defined, but are counterintuitive to what we would expect. Pick either the variable `age` or `rm`, and answer the following questions:

* What do you expect this variable would represent, if the observational units were houses?

Answer: I would expect the variable, age, to represent the age of the house.
* What does this variable actually represent?

Answer: AGE - proportion of owner-occupied units built prior to 1940

* What is the distribution of this variable in the dataset? Include at least one graph to support your answer.

```{r}
Boston %>% 
  ggplot(aes(x = age)) +
  geom_histogram()
```


* Does this variable appear to have a relationship with the response variable `medv`? Include at least one graph to support your answer.

```{r}
Boston %>% 
  ggplot(aes(x = age, y = medv)) +
  geom_point() +
  geom_smooth(method = lm)
```

Based on the above graph there does not seem to be a relationship between our predictor age, and response, median value of owner-occupied home. 


# Problem 3: Simple Linear Regression

## Part a (Code: 0.5 pts; Explanation: 1 pt)

Run the code in ISLR Lab 3.6.2. Put each chunk from the textbook in its own chunk.

```{r}
head(Boston)
```

```{r}
lm.fit <- lm(medv ~lstat, data = Boston)
```

```{r}
lm.fit <- lm(medv ~lstat, data = Boston)
#attach(Boston) I commented this out because I hate using attach but  I understand why we would use it
# lm.fit <- lm(medv âˆ¼ lstat)
```

```{r}
lm.fit

# summarise(lm.fit)
```

```{r}
names(lm.fit)

coef(lm.fit)
```

```{r}
confint(lm.fit)
```

```{r}

predict(lm.fit, data.frame(lstat = (c(5, 10, 15))),interval = "confidence")

predict (lm.fit , data.frame(lstat = (c(5, 10, 15))),interval = "prediction")
```

```{r}
plot(Boston$lstat,Boston$medv)
abline (lm.fit)
```

```{r}
plot(Boston$lstat,Boston$medv)
abline (lm.fit , lwd = 3)
abline (lm.fit , lwd = 3, col = " red ")
plot (Boston$lstat , Boston$medv , col = " red ")
plot (Boston$lstat , Boston$medv , pch = 20) 
plot (Boston$lstat , Boston$medv , pch = "+")
plot (1:20, 1:20, pch = 1:20)
```


```{r}
par(mfrow = c(2, 2))
plot(lm.fit)
```


```{r}
plot ( predict (lm.fit), residuals (lm.fit))
plot ( predict (lm.fit), rstudent (lm.fit))
```

```{r}
plot ( hatvalues (lm.fit))
which.max(hatvalues(lm.fit))
```



Briefly explain what the `confint()` and `predict()` functions output when applied to a linear model.

Answer: "confint()" produces a confidence interval for the coefficient estimates, since these are not known values we estimate them and confint() just allows us to see the spread of possible values. "predict()" on the other hand produces a confidence interval or prediction interval for the prediction of y based on whatever the x variable may be.

## Part b (Explanation: 2.5 pts)

Write out the equation of the least-squares line relating `lstat` and `medv`. Write two sentences interpreting the parameter estimates (one for slope, one for intercept) in the context of the data. Remember to use the right observational units!

medv = 34.55-0.95(lstat) + error

The parameters of this equation is estimating the median value of the owners home in 1000s and our model has estimated that when "% lower status of the population" or in context of the data, "proportion of adults without some high school education and proportion of male workers classified as laborers" is equal to 0 the value is equal to 34,550 dollars. Our variable, "lstat", which again is  "% lower status of the population", for every percentage increase of this value we would expect to see a decrease in the value of the property of approximately 950 dollars.

Given the issue raised in Problem 1d with the `lstat` interpretation, let's just say in our interpretations that `lstat` represents the percentage of people in the neighborhood considered lower class.

Answer: This would then be an incorrect interpretation of the model as this would change the interpretation of our model to be based on class of citizens and not the proportion of adults without some high school education and proportion of male workers classified as laborers

## Part c (Explanation: 1.5 pts)

```{r}
par(mfrow = c(2, 2))
plot(lm.fit)
```

Refer to the diagnostic plots you created in Part (a) to answer the following questions:

* Why do the lab instructions claim that "there is some evidence of non-linearity"?

Answer: Based on the Residuals versus Leverage as well as the residuals versus fitted we see the potential evidence of non-linearity in favor of a skewed right model.

* Do you believe that the residuals are normally distributed? Why or why not?

Answer:Based on our QQ plot our residuals are not likely normally distributed but instead skewed right.

* Do you believe that the response variable is homoskedastic (the residuals have roughly constant variance across the entire predictor range)? Why or why not?

Answer: I do not believe the response variable to be homoskedastic since there seems to be a downward trend in the data regarding residuals versus predicted values.

# Problem 4: Multiple Linear Regression

## Part a (Code: 0.5 pts; Explanation: 1 pt)

Run the code in ISLR Lab 3.6.3. Put each chunk from the textbook in its own chunk. (Note that you will have to install the `car` package.)

```{r}
lm.fit <- lm(data = Boston, medv ~ lstat + age)
summary (lm.fit)
```

```{r}
lm.fit <- lm(data = Boston, medv ~ .)
summary (lm.fit)
```


```{r}
library (car)
vif (lm.fit)
```

```{r}
lm.fit1 <- lm(data = Boston, medv ~ . -age)
summary (lm.fit1)
```

```{r}
lm.fit1 <- update(lm.fit,~.-age)

```



Briefly explain what the `vif()` and `update()` functions do when applied to a linear model.

"vif()" can be used to compute variance inflation factors. the update() function when applied to a linear model updates our model by changing the predictors of the model, in our case it what to keep all others and remove the age variable.


## Part b (Code: 0.5 pts; Explanation: 1 pt)

Jumping straight into modeling without looking at the data is a very bad idea. Create a scatterplot matrix showing only the three variables in the first `lm.fit` object (`medv`, `lstat`, `age`).

```{r}
lm.fit <- lm(data = Boston, medv ~ lstat + age)
scatterplotMatrix(~ medv+lstat + age, data = Boston)
```



Do you see any evidence of nonlinearity? Any evidence of collinearity? Explain your reasoning.

Answer: In the plots of both our x variables, lstat and age, against medv we see clear trends which inclines us to say the relationship between our prediction and response variables are not linear.
